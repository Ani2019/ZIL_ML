{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ifelse](../Images/ifelse.jpg)\n",
    "\n",
    "![blood](../Images/blood_pressure.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![animal_tree](../Images/animal_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree](../Images/tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTs are composed of **nodes, branches and leafs**. Each node represents an attribute (or feature), each branch represents a rule (or decision), and each leaf represents an outcome. The depth of a Tree is defined by the number of levels, not including the root node.\n",
    "![tree_struct](../Images/tree_names.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTs apply a **top-down approach** to data, so that given a data set, they try to group and label observations that are similar between them, and look for the best rules that split the observations that are dissimilar between them until they reach certain degree of similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They use a layered splitting process, where at each layer they try to split the data into two or more groups, so that data that fall into the same group are most similar to each other **(homogeneity)**, and groups are as different as possible from each other **(heterogeneity)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many children can a parent node have? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees can be both  **binary** and **multiway**. \n",
    "\n",
    "![bin_vs_mult](../Images/bin_vs_mult.png)\n",
    "\n",
    "Advantages of multiway splitting\n",
    "\n",
    "* more comprehensible - attributes rarely appearmore than once in any path from root to leaf\n",
    "\n",
    "Disadvantages of multiway splitting\n",
    "\n",
    "* computationally harder\n",
    "* require larger datasets\n",
    "* no scikit-learn implementation\n",
    "* fewer algorithms\n",
    "\n",
    "Check the [Literature](#lit) part for an article about multiway splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive example\n",
    "![gif](../Images/binary_splitting.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How we split? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need a criterion!\n",
    "**Below we will discuss some of them**\n",
    "![mathjoke](../Images/math_joke.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Content\n",
    "\n",
    "Claude Shannon's definition of self-information was chosen to meet several axioms:\n",
    "* An event with probability 100% is perfectly unsurprising and yields no information.\n",
    "* The less probable an event is, the more surprising it is and the more information it yields.\n",
    "* If two independent events are measured separately, the total amount of information is the sum of the self-informations of the individual events.\n",
    "\n",
    "Given an event ${\\displaystyle X}$ with probability ${\\displaystyle P}$, the information content is defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{I}(x):=-\\log _{b}[\\operatorname{Pr}(x)]=-\\log _{b}(P)\n",
    "$$\n",
    "\n",
    "The base of the log is left unspecified, which corresponds to the scaling factor above. Different choices of base correspond to different units of information: **if the logarithmic base is 2, the unit is named the \"bit\"** or \"shannon\"; if the logarithm is the natural logarithm (corresponding to base Euler's number e ≈ 2.7182818284), the unit is called the \"nat\", short for \"natural\"; and if the base is 10, the units are called \"hartleys\", decimal \"digits\", or occasionally \"dits\". \n",
    "\n",
    "Formally, given a random variable ${\\displaystyle X}$ with probability mass function ${\\displaystyle p_{X}{\\left(x\\right)}}$, the self-information of measuring ${\\displaystyle X}$ as outcome ${\\displaystyle x}$ is defined as \n",
    "\n",
    "$$\n",
    "\\mathrm{I}_{X}(x):=-\\log \\left[p_{X}(x)\\right]=\\log \\left(\\frac{1}{p_{X}(x)}\\right)\n",
    "$$\n",
    "\n",
    "If you wօnder what probability mass function was (omg, I hope not !), here is the definition. For ${\\displaystyle -\\infty <x<\\infty }$\n",
    "\n",
    "$$\n",
    "p_{X}\\left(x_{i}\\right)=P\\left(X=x_{i}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "Shannon defined the entropy Η (Greek capital letter eta) of a discrete random variable ${\\textstyle X}$ with possible values ${\\textstyle \\left\\{x_{1},\\ldots ,x_{n}\\right\\}}$ and probability mass function ${\\textstyle \\mathrm {P} (X)}$ as:\n",
    "$$\n",
    "\\mathrm{H}(X)=\\mathrm{E}[\\mathrm{I}(X)]=\\mathrm{E}[-\\log (\\mathrm{P}(X))]\n",
    "$$\n",
    "\n",
    "where $I(X)$ is the information content of X and $E(X)$ is expected value of X. $I(x)$ itself is a random variable. \n",
    "\n",
    "$$\n",
    "\\mathrm{H}(X)=-\\sum_{i=1}^{n} \\mathrm{P}\\left(x_{i}\\right) \\log _{2} \\mathrm{P}\\left(x_{i}\\right)\n",
    "$$\n",
    "\n",
    "Let's derive the second equation from first one.\n",
    "\n",
    "But before, let's revise the definition of expectation, if you \"accidentally\" have forgotten  it (I really hope, you'll remember it from now on):\n",
    "$$\n",
    "\\mathrm{E}[X]=\\sum_{i=1}^{k} x_{i} p_{i}=x_{1} p_{1}+x_{2} p_{2}+\\cdots+x_{k} p_{k}\n",
    "$$\n",
    "\n",
    "So, here we go\n",
    "$$\n",
    "\\mathrm{E}[-\\log (\\mathrm{P}(X)] = -\\mathrm{E}[\\log (\\mathrm{P}(X)] = - \\sum_{X} \\mathrm{P}(X) \\log_{2} \\mathrm{P}(X)\n",
    "$$\n",
    "\n",
    "**Thermodynamic “entropy” and the “entropy” in information theory both capture increasing randomness.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at example.\n",
    "\n",
    "**Normal Coin** \n",
    "$$\n",
    "P(head) = \\frac{1}{2}\n",
    "$$\n",
    "$$\n",
    "P(tail) = \\frac{1}{2}\n",
    "$$\n",
    "$$\n",
    "Entropy = - \\frac{1}{2} \\log_2 \\frac{1}{2} - \\frac{1}{2} \\log_2 \\frac{1}{2} = 1\n",
    "$$\n",
    "\n",
    "**Fake Coin**\n",
    "$$\n",
    "P(head) = 0\n",
    "$$\n",
    "$$\n",
    "P(tail) = 1\n",
    "$$\n",
    "$$\n",
    "Entropy = 0 \\log_2 0 - 1 \\log_2 1 = 0\n",
    "$$\n",
    "\n",
    "![prob_vs_ent](../Images/prob_vs_ent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reformulate the definition.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H(x) &=-\\sum_{x} P(x) \\cdot \\log P(x) =\\sum_{x} P(x) \\cdot \\log \\left(\\frac{1}{P(x)}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* **Why do we take the reciprocal of probability?**\n",
    "* **Why the log?**\n",
    "\n",
    "Let's [CHECK THIS](https://towardsdatascience.com/the-intuition-behind-shannons-entropy-e74820fe9800) to get some intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may also define the **conditional entropy** of two events ${\\displaystyle X}$ and ${\\displaystyle Y}$ taking values ${\\displaystyle x_{i}}$ and ${\\displaystyle y_{j}}$ respectively, as \n",
    "\n",
    "$$\n",
    "\\mathrm{H}(X | Y)=-\\sum_{i, j} p\\left(x_{i}, y_{j}\\right) \\log \\frac{p\\left(x_{i}, y_{j}\\right)}{p\\left(y_{j}\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini\n",
    "Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. The Gini impurity can be computed by summing the probability ${\\displaystyle p_{i}}$ of an item with label ${\\displaystyle i}$ being chosen times the probability ${\\displaystyle \\sum _{k\\neq i}p_{k}=1-p_{i}}$ of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category. \n",
    "\n",
    "To compute Gini impurity for a set of items with ${\\displaystyle J}$ classes, suppose ${\\displaystyle i\\in \\{1,2,...,J\\}}$, and let ${\\displaystyle p_{i}}$ be the fraction of items labeled with class ${\\displaystyle i}$ in the set. \n",
    "\n",
    "$$\n",
    "\\mathrm{I}_{G}(p)=\\sum_{i=1}^{J} p_{i} \\sum_{k \\neq i} p_{k}=\\sum_{i=1}^{J} p_{i}\\left(1-p_{i}\\right)=\\sum_{i=1}^{J}\\left(p_{i}-p_{i}^{2}\\right)=\\sum_{i=1}^{J} p_{i}-\\sum_{i=1}^{J} p_{i}^{2}=1-\\sum_{i=1}^{J} p_{i}^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missclassification Error\n",
    "\n",
    "The classification error rate is simply the fraction of training observations in a region that do not belong to the most common class.\n",
    "\n",
    "$$\n",
    "E=1-\\max \\left(\\hat{p}_{m k}\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "> Information gain is used to decide which feature to split on at each step in building the tree. Simplicity is best, so we want to keep our tree small. To do so, at each step we should choose the split that results in the purest daughter nodes. A commonly used measure of purity is called information which is measured in bits. For each node of the tree, the information value \"represents the expected amount of information that would be needed to specify whether a new instance should be classified yes or no, given that the example reached that node\".\n",
    "\n",
    "**General Definition**\n",
    "\n",
    "In general terms, the expected information gain is the change in information entropy Η from a prior state to a state that takes some information as given: \n",
    "\n",
    "$$\n",
    "I G(T, a)=\\mathrm{H}(T)-\\mathrm{H}(T | a)\n",
    "$$\n",
    "\n",
    "where ${\\displaystyle \\mathrm {H} {(T|a)}}$ is the conditional entropy of ${\\displaystyle T}$ given the value of attribute ${\\displaystyle a}$. \n",
    "\n",
    "**Formal Definition**\n",
    "\n",
    "Let ${\\displaystyle T}$ denote a set of training examples, each of the form ${\\displaystyle ({\\textbf {x}},y)=(x_{1},x_{2},x_{3},...,x_{k},y)}$ where ${\\displaystyle x_{a}\\in vals(a)}$ is the value of the ${\\displaystyle a^{\\text{th}}}$ attribute or feature of example ${\\displaystyle {\\textbf {x}}}$ and y is the corresponding class label. The information gain for an attribute ${\\displaystyle a}$ is defined in terms of Shannon entropy ${\\displaystyle \\mathrm {H} (-)}$ as follows. For a value ${\\displaystyle v}$ taken by attribute ${\\displaystyle a}$, let \n",
    "\n",
    "$$\n",
    "S_{a}(v)=\\left\\{\\mathbf{x} \\in T | x_{a}=v\\right\\}\n",
    "$$\n",
    "\n",
    "be defined as the set of training inputs of ${\\displaystyle T}$ such for which attribute ${\\displaystyle a}$ is equal to ${\\displaystyle v}$. Then the information gain of ${\\displaystyle T}$ for attribute ${\\displaystyle a}$ is the difference between the a priori Shannon entropy ${\\displaystyle \\mathrm {H} (T)}$ of the training set and the conditional entropy ${\\displaystyle \\mathrm {H} {(T|a)}}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mathrm{H}(T | a)=\\sum_{v \\in v a l s(a)} \\frac{\\left|S_{a}(v)\\right|}{|T|} \\cdot \\mathrm{H}\\left(S_{a}(v)\\right)\\\\\n",
    "&I G(T, a)=\\mathrm{H}(T)-\\mathrm{H}(T | a)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The mutual information is equal to the total entropy for an attribute if for each of the attribute values a unique classification can be made for the result attribute. In this case, the relative entropies subtracted from the total entropy are 0. In particular, the values ${\\displaystyle v\\in vals(a)}$ defines a partition of the training set data ${\\displaystyle T}$ into mutually exclusive and all-inclusive subsets, inducing a categorical probability distribution ${\\textstyle P_{a}{(v)}}$ on the values ${\\textstyle v\\in vals(a)}$ of attribute ${\\displaystyle a}$. The distribution is given ${\\textstyle P_{a}{(v)}:={\\frac {|S_{a}{(v)}|}{|T|}}}$. In this representation, the information gain of ${\\displaystyle T}$ given ${\\displaystyle a}$ can be defined as the difference between the unconditional Shannon entropy of ${\\displaystyle T}$ and the expected entropy of ${\\displaystyle T}$ conditioned on ${\\displaystyle a}$, where the expectation value is taken with respect to the induced distribution on the values of ${\\displaystyle a}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "I G(T, a) &=\\mathrm{H}(T)-\\sum_{v \\in v a l s(a)} P_{a}(v) \\mathrm{H}\\left(S_{a}(v)\\right) \\\\\n",
    "&=\\mathrm{H}(T)-\\mathbb{E}_{P_{a}}\\left[\\mathrm{H}\\left(S_{a}(v)\\right)\\right] \\\\\n",
    "&=\\mathrm{H}(T)-\\mathrm{H}(T | a)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's check [this example](https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain) on Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain Generally\n",
    "## Comparison Between Entropy, Gini and Misclf Error as Impurity Measures\n",
    "\n",
    "Generally, our Goal is to maximise the Information Gain at each Split.\n",
    "\n",
    "$$\n",
    "I G\\left(D_{p}, f\\right)=I\\left(D_{p}\\right)-\\sum_{j=1}^{m} \\frac{N_{j}}{N} I\\left(D_{j}\\right)\n",
    "$$\n",
    "\n",
    "where $f$ is the feature to perform the split, and $D_p$ and $D_j$ are the datasets of the parent and $j^{th}$ child node, respectively. $I$ is the impurity measure. $N$ is the total number of samples, and $N_j$ is the number of samples at the $j^{th}$ child node. \n",
    "\n",
    "> **Information gain is simply the difference between the impurity of the parent node and the sum of the child node impurities — the lower the impurity of the child nodes, the larger the information gain**\n",
    " \n",
    "We will consider binary classification, thus Information Gain looks like following.\n",
    "\n",
    "$$\n",
    "I G\\left(D_{p}, a\\right)=I\\left(D_{p}\\right)-\\frac{N_{\\text {left}}}{N} I\\left(D_{\\text {left}}\\right)-\\frac{N_{\\text {right}}}{N} I\\left(D_{\\text {right}}\\right)\n",
    "$$\n",
    "\n",
    "![inf_gain](../Images/inf_gain.png)\n",
    "\n",
    "We will discusss three Impurity Measures:\n",
    "1. **Entropy**\n",
    "$\n",
    "I_{H}(t)=-\\sum_{i=1}^{c} p(i | t) \\log _{2} p(i | t)\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "2. **Gini**\n",
    "$\n",
    "I_{G}(t)=\\sum_{i=1}^{c} p(i | t)(1-p(i | t))=1-\\sum_{i=1}^{c} p(i | t)^{2}\n",
    "$\n",
    "\n",
    "\n",
    "3. **Misclassification Error**\n",
    "$\n",
    "I_{E}=1-\\max \\{p(i | t)\\}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Let's demonstrate the comparison on the following example**\n",
    "![AB](../Images/data_A_B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures of Impurity Measures\n",
    "\n",
    "![crit_graph](../Images/criterion_graph.png)\n",
    "\n",
    "1. **Gini’s maximum impurity is 0.5 and maximum purity is 0**\n",
    "2. **Entropy’s maximum impurity is 1 and maximum purity is 0**\n",
    "3. **Misclf Error's maximum impurity is 0.5 and maximum purity is 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Criteria for Regression Trees will be discussed in the following block.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Scikit-learn Examples and General Setup\n",
    "\n",
    "Here we will discuss \n",
    "* Regression and Classification Decision Tree Mathematical Formulations\n",
    "* Usage Examples in Scikit-learn\n",
    "* Decision Boundaries\n",
    "* Multi-output Problems\n",
    "\n",
    "Let's [CHECK THIS](https://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantanges of DTs\n",
    "\n",
    "* Simple to understand and to interpret. Trees can be visualised.\n",
    "\n",
    "* Requires little data preparation. Other techniques often require data normalisation, dummy variables need to be created and blank values to be removed. Note however that this module does not support missing values.\n",
    "\n",
    "* Able to handle both numerical and categorical data. Other techniques are usually specialised in analysing datasets that have only one type of variable. See algorithms for more information.\n",
    "\n",
    "* Able to handle multi-output problems.\n",
    "\n",
    "* Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.\n",
    "\n",
    "* Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.\n",
    "\n",
    "* Performs well even if its assumptions are somewhat violated by the true model from which the data were generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![danger_zone](../Images/danger_zone.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting ALERT!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting. Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Disadvantages of DTs.\n",
    "* **high variance** - a small change in the data can result in a very different set of splits, thus resulting  in a completely different tree being genrated\n",
    "* **inherent instability** - since due to their hierarchical nature, the effect of an error in the top splits propagate down to all of the splits below\n",
    "* **biased trees** - when some classes dominate over others. This is a problem in unbalanced datasets (where different classes in the dataset have different number of observations), in which case it is recommended to balance de dataset prior to building the DT.\n",
    "* **boundaries on the values they can produce** - In the case of Regression Trees, DTs can only predict within the range of values they created based on the data they saw before\n",
    "* **can't learn some concepts** - There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems\n",
    "* **greediness leads to local optima** - DTs splitting algorithms can’t see far beyond the current level in which they are operating (they are **\"greedy\"**), which means that they look for a locally optimal and not a globally optimal at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which is better Linear or tree-based models?\n",
    "\n",
    "It depends on the kind of problem you are solving.\n",
    "\n",
    "* If the relationship between dependent & independent variables is well approximated by a linear model, linear regression will outperform the tree-based model.\n",
    "* If there is a high non-linearity & complex relationship between dependent & independent variables, a tree model will outperform a classical regression method.\n",
    "* If you need to build a model that is easy to explain to people, a decision tree model will always do better than a linear model. Decision tree models are even simpler to interpret than linear regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to fight Overfitting?\n",
    "![later](../Images/later.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"lit\"></a> **Literature**\n",
    "\n",
    "* Paper about multiway classification https://www.cs.waikato.ac.nz/~eibe/pubs/multiway.pdf\n",
    "* Visual Information Theory http://colah.github.io/posts/2015-09-Visual-Information/\n",
    "* Guide https://towardsdatascience.com/the-complete-guide-to-decision-trees-28a4e3c7be14\n",
    "* Guide https://towardsdatascience.com/decision-tree-algorithm-explained-83beb6e78ef4\n",
    "* Guide with Regression Tree example https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054\n",
    "* Entropy explained https://www.inovex.de/blog/the-mystery-of-entropy-how-to-measure-unpredictability-in-machine-learning/\n",
    "* Information Gain with Entropy https://victorzhou.com/blog/information-gain/\n",
    "* IG-Gini VS IG-Entropy https://towardsdatascience.com/gini-index-vs-information-entropy-7a7e4fed3fcb \n",
    "* Metrics https://en.wikipedia.org/wiki/Decision_tree_learning#Metrics\n",
    "* Metrics Comparison https://github.com/rasbt/python-machine-learning-book/blob/master/faq/decision-tree-binary.md\n",
    "\n",
    "* And your humble servant **Wikipedia**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
