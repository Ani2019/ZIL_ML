{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feature Matrix](../Images/X_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{y}=\\left(\\begin{array}{c}{y_{1}} \\\\ {y_{2}} \\\\ {\\vdots} \\\\ {y_{m}}\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\theta}=\\left(\\begin{array}{c}{\\theta_{1}} \\\\ {\\theta_{2}} \\\\ {\\vdots} \\\\ {\\theta_{n}}\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $g(z)$: Logistic(sigmoid) function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_{\\theta}(x)=g\\left(\\theta^{T} x\\right)=\\frac{1}{1+e^{-\\theta^{T} x}},$$\n",
    "where\n",
    "$$g(z)=\\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/sigmoid.png\" alt=\"Sigmoid\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful property of the derivative of the sigmoid function:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g^{\\prime}(z) &=\\frac{d}{d z} \\frac{1}{1+e^{-z}} \\\\\n",
    "&=\\frac{1}{\\left(1+e^{-z}\\right)^{2}}\\left(e^{-z}\\right) \\\\\n",
    "&=\\frac{1}{\\left(1+e^{-z}\\right)} \\cdot\\left(1-\\frac{1}{\\left(1+e^{-z}\\right)}\\right) \\\\\n",
    "&=g(z)(1-g(z))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us assume that\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "{P(y=1  | x ; \\theta)=h_{\\theta}(x)} \\\\\n",
    "{P(y=0  | x ; \\theta)=1-h_{\\theta}(x)}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More compactly \n",
    "$$\n",
    "p(y | x ; \\theta)=\\left(h_{\\theta}(x)\\right)^{y}\\left(1-h_{\\theta}(x)\\right)^{1-y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta) &=p(\\vec{y} | X ; \\theta) \\\\\n",
    "&=\\prod_{i=1}^{m} p\\left(y^{(i)} | x^{(i)} ; \\theta\\right) \\\\\n",
    "&=\\prod_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)\\right)^{y^{(i)}}\\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)^{1-y^{(i)}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-likelihood:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ell(\\theta) &=\\log L(\\theta) \\\\\n",
    "&=\\sum_{i=1}^{m} y^{(i)} \\log h\\left(x^{(i)}\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h\\left(x^{(i)}\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-liklihood needs to be maximized. Maximizing $\\ell(\\theta)$ is the same as minimizing $-\\ell(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function:\n",
    "$$\n",
    "J(\\theta)= -\\frac{1}{m} \\ell(\\theta)  =-\\frac{1}{m}\\left[\\sum_{i=1}^{m} y^{(i)} \\log h_{\\theta}\\left(x^{(i)}\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function in matrix form:\n",
    "$$\n",
    "J(\\theta)=\\frac{1}{m} \\cdot\\left[-y^{T} \\log (h_{\\theta}(X))-(1-y)^{T} \\log (1-h_{\\theta}(X))\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta:=\\theta - \\alpha \\nabla_{\\theta} J(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial \\theta_{j}} \\ell(\\theta) &=\\left(y \\frac{1}{g\\left(\\theta^{T} x\\right)}-(1-y) \\frac{1}{1-g\\left(\\theta^{T} x\\right)}\\right) \\frac{\\partial}{\\partial \\theta_{j}} g\\left(\\theta^{T} x\\right) \\\\\n",
    "&=\\left(y \\frac{1}{g\\left(\\theta^{T} x\\right)}-(1-y) \\frac{1}{1-g\\left(\\theta^{T} x\\right)}\\right) g\\left(\\theta^{T} x\\right)\\left(1-g\\left(\\theta^{T} x\\right)\\right) \\frac{\\partial}{\\partial \\theta_{j}} \\theta^{T} x \\\\\n",
    "&=\\left(y\\left(1-g\\left(\\theta^{T} x\\right)\\right)-(1-y) g\\left(\\theta^{T} x\\right)\\right) x_{j} \\\\\n",
    "&=\\left(y-h_{\\theta}(x)\\right) x_{j}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta_{j}:=\\theta_{j}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x^{(i)}\\right)-y^{(i)}\\right) x_{j}^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient of loss function in matrix form:\n",
    "$$\n",
    "\\nabla_{\\theta} J(\\theta)=\\frac{1}{m} \\cdot X^{T}(h_{\\theta}(X)-y)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
