{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla GAN (Generative Adversarial Network)\n",
    "\n",
    "![gan](../Images/gan.svg)\n",
    "\n",
    "It is like a 2-player game:\n",
    "**Generator** tries to generate real looking samples and fool the discriminator.\n",
    "**Dicriminator** tries to distinguishe between real and fake data generated by generator.\n",
    "\n",
    "As proposed in the [original paper](https://arxiv.org/pdf/1406.2661.pdf), GAN's used to have the so called minimax loss.\n",
    "![minimax](../Images/gan_minimax_loss.png)\n",
    "\n",
    "GAN training conists of Generator(G) and Discriminator(D) trainings. We fix  G and train D, then fix D and train G. As G improves over time,  D's performance of distinguishing between real and fake data gets worse. Ideally D will give 50% probabilities which means it will make a random guess.\n",
    "\n",
    "**GAN training steps:**\n",
    "1. The discriminator trains for one or more epochs.\n",
    "2. The generator trains for one or more epochs.\n",
    "3. Repeat steps 1 and 2 to continue to train the generator and discriminator networks.\n",
    "\n",
    "**Useful Links**\n",
    "* https://developers.google.com/machine-learning/gan/gan_structure\n",
    "* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occuring Problems\n",
    "\n",
    "### Mode Collapse\n",
    "\n",
    "The analogous of overfitting is mode collapse when generator generates only some set of samples.\n",
    "\n",
    "![meme](../Images/baozou.png)\n",
    "\n",
    "![modecollapse](../Images/meme_collapse.png)\n",
    "\n",
    "### Vanishing Gradient\n",
    "\n",
    "Gradient vanishing is a common problem in deep architectures. Here the risk \"doubles\" as teh gradients must flow both into discriminator and generator networks.\n",
    "\n",
    "### Lack of Evaluation Metric\n",
    "\n",
    "It is hard to tell when it converges: loss doesn't tell much here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of GANs\n",
    "\n",
    "## DCGAN ( Deep Convolutional GAN)\n",
    "\n",
    "Original paper [here](https://arxiv.org/pdf/1511.06434.pdf)\n",
    "\n",
    "To ensure the stable training of GANs on image data like this, a DCGAN uses three techniques:\n",
    "* Getting rid of fully connected layers and only using convolution layers\n",
    "* Using strided convolution layers to perform downsampling, instead of using pooling layers\n",
    "* Using ReLU/leakyReLU activation functions instead of Tanh between hidden layers\n",
    "\n",
    "![dcgan_g](../Images/dcgan_g.png)\n",
    "![dcgan_d](../Images/dcgan_d.png)\n",
    "![dcgan_guide](../Images/dcgan_guide.png)\n",
    "![dcgan_mnist](../Images/dcgan_mnist.png)\n",
    "\n",
    "## CGAN (Conditional GAN)\n",
    "\n",
    "Original paper [here](https://arxiv.org/pdf/1411.1784.pdf)\n",
    "\n",
    "> Generative adversarial nets can be extended to a conditional model if both the generator and discrim-inator are conditioned on some extra informationy.ycould be any kind of auxiliary information,such as class labels or data from other modalities.  We can perform the conditioning by feedingyinto the both the discriminator and generator as additional input layer.\n",
    "\n",
    "![cgan_g](../Images/cgan_g.png)\n",
    "![cgan_d](../Images/cgan_d.png)\n",
    "![cgan_mnist](../Images/cgan_mnist.png)\n",
    "![cgan_fashion](../Images/cgan_fashion.png)\n",
    "\n",
    "## InfoGAN \n",
    "\n",
    "Original paper [here](https://arxiv.org/pdf/1606.03657.pdf)\n",
    "\n",
    "Helper explanation [here](https://medium.com/deep-math-machine-learning-ai/ch-14-1-types-of-gans-with-math-5b0dbc1a491d)\n",
    "\n",
    "\n",
    "## UnrolledGAN\n",
    "\n",
    "Original paper [here](https://arxiv.org/pdf/1611.02163.pdf)\n",
    "\n",
    "Helper explanation [here](https://medium.com/@jonathan_hui/gan-unrolled-gan-how-to-reduce-mode-collapse-af5f2f7b51cd)\n",
    "\n",
    "## pix2pix\n",
    "\n",
    "Original paper [here](https://arxiv.org/pdf/1611.07004.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
