{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial deffinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a data set $ ( x_{1},..., x_{N} ) $ consisting\n",
    "of N observations of a random D-dimensional Euclidean variable $x$.\n",
    "\n",
    "$$ X= \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{11} & \\cdots & x_{1d}  \\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2d} \\\\\n",
    "x_{n1} & x_{n2} & \\cdots & x_{nd} \n",
    "\\end{bmatrix}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Our goal is to partition the data set into some number K of clusters, where we shall suppose for the moment that the value of K is given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering:\n",
    "\n",
    "<br> The process of grouping a set of objects into classes of similar objects <br>\n",
    "1. high intra-class similarity\n",
    "2. low inter-class similarity\n",
    "3. It is the most common form of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![clustering](../Images/task.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can formalize this notion by first introducing a set of $D-dimensional$ vectors $\\mu_{k}$, where $k = 1,...,K$, in which $\\mu_{k}$ is a prototype associated with the $k_{th}$ cluster. As we shall see shortly, we can\n",
    "think of the $\\mu_{k}$ as representing the centres of the clusters. Our goal is then to find\n",
    "an assignment of data points to clusters, as well as a set of vectors {$\\mu_{k}$}, such that\n",
    "the sum of the squares of the distances of each data point to its closest vector $\\mu_{k}$, is\n",
    "a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data point $x_{n}$, we introduce a corresponding set\n",
    "of binary indicator variables $r_{nk} \\in \\{0, 1\\}$, where $k = 1,...,K$ describing which of\n",
    "the K clusters the data point $x_{n}$ is assigned to, so that if data point $x_{n}$ is assigned to\n",
    "cluster $k$ then $r_{nk} = 1$, and $r_{nj} = 0$ for $j \\neq  k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define an objective function, sometimes called a distortion\n",
    "measure, given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J=\\sum_{n=1}^{N} \\sum_{k=1}^{K} r_{n k}\\left\\|\\mathbf{x}_{n}-\\boldsymbol{\\mu}_{k}\\right\\|^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this through an iterative procedure in which each iteration\n",
    "involves two successive steps corresponding to successive optimizations with respect\n",
    "to the $r_{nk}$ and the $\\mu_{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizing $J$ with respect to $r_{nk}$\n",
    "\n",
    "Consider first the determination of the $r_{nk}$. Because $J$ is a linear function of $r_{nk}$, this optimization can be performed easily to give a closed form solution.\n",
    "\n",
    "\\begin{equation}\n",
    "r_{n k}=\\left\\{\\begin{array}{ll}\n",
    "1 & \\text { if } k=\\arg \\min _{j}\\left\\|\\mathbf{x}_{n}-\\boldsymbol{\\mu}_{j}\\right\\|^{2} \\\\\n",
    "0 & \\text { otherwise }\n",
    "\\end{array}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizing $J$ with respect to $\\mu_{k}$\n",
    "\n",
    "Now consider the optimization of the $\\mu_k$ with the $r_{nk}$ held fixed. The objective\n",
    "function $J$ is a quadratic function of $\\mu_k$, and it can be minimized by setting its\n",
    "derivative with respect to  $\\mu_k$ to zero giving\n",
    "\n",
    "\\begin{equation}\n",
    "2 \\sum_{n=1}^{N} r_{n k}\\left(\\mathbf{x}_{n}-\\boldsymbol{\\mu}_{k}\\right)=0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\mu}_{k}=\\frac{\\sum_{n} r_{n k} \\mathbf{x}_{n}}{\\sum_{n} r_{n k}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator in this expression is equal to the number of points assigned to\n",
    "cluster k, and so this result has a simple interpretation, namely set Âµk equal to the\n",
    "mean of all of the data points xn assigned to cluster k. For this reason, the procedure\n",
    "is known as the K-means algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Randomly initialize  $\\mu_k$ centers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kmeans0](../Images/k_means_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  For each example finde $r_{nk}$\n",
    "Iterate over all data examples, and for each point find nearest $\\mu_{k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kmeans1](../Images/k_means_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Recalcualte means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kmeans2](../Images/k_means_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Repeat 2 and 3 until to converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kmeans2](../Images/k_means_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kmeans4](../Images/k_means_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose k \n",
    "\n",
    "## elbow method \n",
    "\n",
    "![kmeans4](../Images/J_vs_k.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on (R,G,B) image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kmeans4](../Images/bishop.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
